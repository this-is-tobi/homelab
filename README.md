# Homelab :alembic:

This projects aims to build a homelab for personnal tests on infrastructure, development, CI/CD, etc...

## Hardware

- 9 x Raspberry (Pi 4 model B - 8GB)
- 1 x Raspberry (Pi 4 model B - 4GB)
- 3 x Switch TP-Link (TL-SG 105E)
- 4 x 2TB HDD (HDTP320EK3AA)

All raspberries are running with `Raspberry Pi OS (64-bit)` (*cf. <https://www.raspberrypi.com/software/operating-systems/>*).

## Infrastructure

### Gateway

A host is configured as the gateway to the local network (*i.e handle all incoming traffic*). It runs various services deployed via docker :

- [Openvpn](https://openvpn.net/) for external access to the local network (*i.e from internet*). An openvpn client conf is generated for each admin user declared in ansible `group_vars`.
- [Haproxy](https://www.haproxy.org/) for loadbalancing all incoming external requests (*ports 80 & 443*) to the k3s cluster and loadbalancing k3s api server (*port 6443*).
- [Crowdsec](https://www.crowdsec.net/) for security purpose as it acts as a community firewall.

Gateway web interface services are available on local network at :

| Name               | Url                                 |
| ------------------ | ----------------------------------- |
| Crowdsec dashboard | <http://crowdsec.domain.local:3000> |
| Haproxy dashboard  | <http://haproxy.domain.local:8404>  |

### Bastion

A host is configured as the bastion to access kubernetes ressources. As previously mentioned, an openvpn profile conf is autogenerated for every `bastion_users` set in [group_vars/all.yml](./ansible/inventory-example/group_vars/bastion.yml).

Bastion is available on the local network using ssh :

1. Connect to the vpn using the proper autogenerated openvpn user profile conf.
2. Connect to the bastion using `ssh <username>@<bastion_ip> -i <ssh_key>`.


### K3S cluster

Some hosts are configrured to run [k3s](https://k3s.io) (*Lightweight Kubernetes*) with the following roles :
- 3 x master nodes
- 5 x worker nodes

The cluster comes with k3s integrated [klipper](https://github.com/k3s-io/klipper-lb) loadbalancer and [traefik](https://traefik.io/) ingressController.

#### Services

The following services are deployed in the cluster :

| Name                                                            | Description                            | Helm chart                                                                                                    |
| --------------------------------------------------------------- | -------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| [Cert-manager](https://cert-manager.io/)                        | Cloud native certificate management    | [cert-manager/cert-manager](https://artifacthub.io/packages/helm/cert-manager/cert-manager)                   |
| [Grafana](https://grafana.com/)                                 | Observability dashboards               | [bitnami/grafana](https://artifacthub.io/packages/helm/bitnami/grafana)                                       |
| [Harbor](https://goharbor.io/)                                  | Cloud native registry                  | [bitnami/harbor](https://artifacthub.io/packages/helm/bitnami/harbor)                                         |
| [Kubernetes-dashboard](https://github.com/kubernetes/dashboard) | Kubernetes dashboard                   | [k8s-dashboard/kubernetes-dashboard](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard) |
| [Longhorn](https://longhorn.io/)                                | Cloud native distributed block storage | [longhorn/longhorn](https://artifacthub.io/packages/helm/longhorn/longhorn)                                   |
| [Minio](https://min.io/)                                        | High Performance Object Storage        | [bitnami/minio](https://artifacthub.io/packages/helm/bitnami/minio)                                           |
| [Prometheus](https://prometheus.io/)                            | Open-source monitoring solution        | [bitnami/kube-prometheus](https://artifacthub.io/packages/helm/bitnami/kube-prometheus)                       |

The services are accessible through the following urls :

| Name                 | Url                            |
| -------------------- | ------------------------------ |
| Grafana              | <https://grafana.domain.com>   |
| Harbor               | <https://registry.domain.com>  |
| Kubernetes-dashboard | <https://console.domain.com>   |
| Longhorn             | <http://longhorn.domain.local> |
| Minio *- api*        | <https://api.minio.domain.com> |
| Minio *- web*        | <https://minio.domain.com>     |
| Traefik              | <http://traefik.domain.local>  |

## Installation

The whole installation is performed with [ansible](https://www.ansible.com/) so it is required to install it on the computer that will run playbooks. Also, ssh access to all hosts need to be setup.

> __*Notes*__: 
> 
> *Don't forget to replace `domain.com` and `domain.local` with the appropriate domain.*

### Prerequisites

For convenience, it is recommended to do these prerequisite steps :

```sh
# Add gateway into /etc/hosts
[ ! $(sudo grep -q "192.168.0.110" /etc/hosts) ] && sudo sh -c "echo $'\n# Homelab\n192.168.0.110   crowdsec.domain.local haproxy.domain.local longhorn.domain.local traefik.domain.local' >> /etc/hosts"

# Copy inventory example to inventory
cp -R ./ansible/inventory-example ./ansible/inventory
```

Because crowdsec is used as the firewall, it is required to [create an account](https://app.crowdsec.net/).

### Settings

Update the [hosts file](./ansible/inventory-example/hosts.yml) and [group_vars files](./ansible/inventory-example/group_vars/) to provide the appropriate infra and services settings.

To create user access to the bastion, it is required to provide their informations in the `groups_vars/all.yml` file :
- Set `setup: true` to setup the working environment for the given user
- Add users ssh public key following the file structure `./secrets/ssh/<bastion_username>.pub`, this will add the appropriate key in the matching bastion user `authorized_keys`.

> __*Notes*__: 
> 
> *Some values are autogenerated and fetch during the ansible install process :*
> - *k3s_token*
> - *kubernetes_dashboard_token*

### Deploy

Various tags are available [here](./ansible/inventory-example/hosts.yml), the main ones are :

```sh
# Deploy bastion
./run.sh -p -t "bastion"

# Deploy gateway
./run.sh -p -t "gateway"

# Deploy cluster
./run.sh -p -t "k3s"

# Deploy all
./run.sh -p
```

> __*Notes*__: 
> 
> *Multiple tags can be passed as follows :* `./run.sh -p -t "gateway,k3s"`
> 
> *First gateway init can take a long time to run because of openvpn key genereration (5-10min).*

### Destroy

It is possible to cleanly detroy the k3s cluster by running :

```sh
# Destroy cluster
./run.sh -p -t "k3s-destroy"
```

## Cheat Sheet

See [there](./docs/cheat-sheet.md).
